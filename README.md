# Smart Summary App

A full-stack application that allows users to paste a block of text and receive a summary generated by a Large Language Model (LLM).

## Project Structure

This is a monorepo containing:

- `apps/frontend`: Next.js frontend application with TypeScript and Tailwind CSS
- `apps/backend`: FastAPI backend service with Python

## Features

- Text summarization using LLM technology
- Real-time streaming of summary results
- Clean, responsive UI
- Error handling and validation
- Character and word count statistics

## Tech Stack

### Frontend

- Next.js with TypeScript
- Tailwind CSS for styling
- React hooks for state management
- Fetch API for data fetching and streaming

### Backend

- FastAPI (Python)
- OpenAI API integration (configurable for other LLM providers)
- Server-sent events for streaming responses
- Environment-based configuration

## Setup Instructions

### Prerequisites

- Node.js (v16+)
- Python (v3.8+)
- npm or yarn
- OpenAI API key (or another LLM provider API key)

### Quick Setup

For a quick setup of both frontend and backend:

```bash
# Clone the repository
git clone https://github.com/yourusername/smart-summary-app.git
cd smart-summary-app

# Install all dependencies (frontend and root)
npm run install:all

# Set up backend
npm run setup:backend

# Configure your OpenAI API key
# Edit apps/backend/.env and add your API key
# OPENAI_API_KEY=your_api_key_here

# Start both services
npm run dev
```

### Frontend Setup

```bash
# Navigate to the frontend directory
cd apps/frontend

# Install dependencies
npm install

# Create a .env.local file with the API URL
echo "NEXT_PUBLIC_API_URL=http://localhost:8000" > .env.local

# Start the development server
npm run dev
```

The frontend will be available at http://localhost:3000

### Backend Setup

```bash
# Navigate to the backend directory
cd apps/backend

# Create a virtual environment (optional but recommended)
python -m venv venv

# Activate the virtual environment
# On Windows:
venv\Scripts\activate
# On macOS/Linux:
# source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Create a .env file with your API keys
# Copy the example file and edit it
cp .env.example .env
# Edit the .env file to add your OpenAI API key

# Start the development server
python run.py
```

The API will be available at http://localhost:8000

### Running Both Services

From the project root, after installing dependencies:

```bash
# Run both services
npm run dev
```

## Testing the Application

Once both the frontend and backend are running, you can test the application:

1. Open your browser and navigate to http://localhost:3000
2. Click on "Get Started" or navigate to http://localhost:3000/summarize
3. Paste a block of text in the input field
4. Click "Summarize (Stream)" to see the summary generated in real-time or "Summarize (Regular)" for a standard request

### Sample Text for Testing

Here's a sample text you can use to test the application:

```
Urban gardening has become increasingly popular as cities grow and people seek sustainable ways to grow their own food. This practice involves growing plants in urban environments, including rooftops, balconies, and small community spaces. Urban gardens help reduce food miles, provide fresh produce, and create green spaces that benefit both the environment and community well-being.

Many urban gardeners focus on growing herbs, vegetables, and small fruits that can thrive in container gardens or small plots. Popular choices include tomatoes, lettuce, herbs like basil and parsley, and fruits like strawberries. These plants are well-suited for urban environments and provide meaningful harvests even in limited space.

Urban gardening also offers educational opportunities for children and adults to learn about plant biology, sustainable practices, and food production. Community gardens foster social connections and provide shared spaces where neighbors can collaborate and share knowledge about growing techniques.
```

## API Endpoints

### GET /

- Returns a simple message indicating the API is running

### GET /health

- Health check endpoint

### POST /summarize

- Accepts a JSON body with `text`, `max_length` (optional), and `model` (optional)
- Returns a summary of the provided text

### POST /summarize/stream

- Accepts the same parameters as `/summarize`
- Returns a server-sent event stream with the summary tokens

## Architecture

The application follows a client-server architecture:

1. **Frontend (Next.js)**

   - User interface for text input and summary display
   - Communicates with backend API
   - Handles both regular and streaming responses

2. **Backend (FastAPI)**

   - Receives requests from frontend
   - Processes text using LLM service
   - Returns responses (regular or streaming)

3. **LLM Integration**
   - Abstracts the LLM provider behind a service interface
   - Currently uses OpenAI but can be extended to other providers

## Future Improvements

- User authentication and saved summaries
- Multiple LLM provider options
- Customization options (summary length, style, etc.)
- Caching for repeated requests
- Analytics for usage tracking
- Mobile app version

## Scaling and Security Considerations

### Scaling

- Horizontal scaling for increased load
- Caching layer for repeated requests
- Rate limiting for API endpoints
- Asynchronous processing for long texts

### Security

- Input validation and sanitization
- API key rotation
- Environment-based configuration
- CORS configuration for production
- Rate limiting to prevent abuse
- Proper error handling to avoid information leakage

## Quick Start with Docker

### Prerequisites

- Docker and Docker Compose installed
- OpenAI API key

### Setup

1. **Clone the repository**

   ```bash
   git clone <your-repo-url>
   cd smart-summary-app
   ```

2. **Set up environment variables**

   ```bash
   # Create .env file
   echo "OPENAI_API_KEY=your_openai_api_key_here" > .env
   ```

3. **Run with Docker Compose**

   ```bash
   docker-compose up --build
   ```

4. **Access the application**
   - Frontend: http://localhost:3000
   - Backend API: http://localhost:8000

### Docker Commands

```bash
# Build and start all services
docker-compose up --build

# Run in background
docker-compose up -d

# Stop all services
docker-compose down

# View logs
docker-compose logs

# Rebuild specific service
docker-compose build backend
docker-compose build frontend
```

## Development Setup

### Prerequisites

- Node.js 22+
- Python 3.12+
- OpenAI API key

### Local Development

1. **Install dependencies**

   ```bash
   npm install
   ```

2. **Set up environment**

   ```bash
   echo "OPENAI_API_KEY=your_openai_api_key_here" > .env
   ```

3. **Start development servers**

   ```bash
   npm run dev
   ```

4. **Access the application**
   - Frontend: http://localhost:3000
   - Backend: http://localhost:8000

## Project Structure

```
smart-summary-app/
â”œâ”€â”€ apps/
â”‚   â”œâ”€â”€ backend/          # FastAPI backend
â”‚   â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”‚   â”œâ”€â”€ main.py           # API endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ models.py         # Data models
â”‚   â”‚   â”‚   â””â”€â”€ services/
â”‚   â”‚   â”‚       â””â”€â”€ llm_service.py # OpenAI integration
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â””â”€â”€ requirements.txt
â”‚   â””â”€â”€ frontend/         # Next.js frontend
â”‚       â”œâ”€â”€ src/
â”‚       â”‚   â””â”€â”€ app/
â”‚       â”‚       â””â”€â”€ page.tsx      # Main application
â”‚       â”œâ”€â”€ Dockerfile
â”‚       â””â”€â”€ package.json
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ package.json
```

## API Endpoints

- `GET /health` - Health check
- `GET /example` - Get example text
- `POST /summarize` - Summarize text

## Environment Variables

- `OPENAI_API_KEY` - Your OpenAI API key (required)
- `NEXT_PUBLIC_API_URL` - Backend API URL (default: http://localhost:8000)

## Technology Stack

- **Frontend**: Next.js 15, React, TypeScript, Tailwind CSS
- **Backend**: FastAPI, Python 3.12, OpenAI API
- **Deployment**: Docker, Docker Compose

## Features

### Smart Caching

- Caches up to 50 previous summaries
- Instant results for repeated text
- Automatic cleanup of old entries

### User Experience

- Paste detection anywhere on the page
- Loading states with animated spinner
- Copy to clipboard functionality
- Responsive design for all devices

## Deployment

### AWS Deployment Options

1. **AWS Lightsail** (Recommended for simple deployments)

   - Create a Lightsail instance
   - Install Docker and Docker Compose
   - Clone repository and run `docker-compose up -d`

2. **AWS ECS Fargate**

   - Push images to ECR
   - Create ECS task definitions
   - Deploy with Application Load Balancer

3. **AWS EC2**
   - Launch EC2 instance
   - Install Docker and Docker Compose
   - Clone repository and run `docker-compose up -d`

### Production Considerations

- Set up proper SSL certificates
- Configure environment variables securely
- Set up monitoring and logging
- Use a reverse proxy (nginx) for production
- Configure proper CORS settings

## Deployed Version

ðŸš€ **Live Demo**: Currently deployed on AWS EC2 with domain setup in progress

- **Production URL**: `https://pastetosummary.com` (when domain is configured)
- **Deployment Platform**: AWS EC2 with Docker Compose
- **SSL Certificate**: AWS Certificate Manager
- **Updates**: Automated via deployment scripts

### Deployment Status

- âœ… Backend API deployed and running
- âœ… Frontend application deployed
- ðŸ”„ Domain configuration in progress
- ðŸ”„ SSL certificate setup in progress

## License

MIT License
